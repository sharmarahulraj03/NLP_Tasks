{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_3(B)_DTI5125_Rahul_Raj_Sharma.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMCP3/Mwu2pauhAV1aQvkQh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sharmarahulraj03/NLP_Tasks/blob/main/Assignment_3(B)_DTI5125_Rahul_Raj_Sharma.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJ86VgAAzy85"
      },
      "source": [
        "<H1 align=\"center\"><b>Data Science Applications</b></H1>\r\n",
        "<H3 align=\"center\"><b>Assignment 3</b></H3>\r\n",
        "<H5 align=\"left\"><b><u> Introduction:</u></b></H5>\r\n",
        "<p align=\"justify\">This assignment should be completed individually using either Python or R. Upon completion, present your result in one submission, including the report, answers generated and plots. Also, submit the source\r\n",
        "codes used to generate your results as a separate attachment.\r\n",
        "</p>\r\n",
        "<H5 align=\"left\"><b><u>Task 2: (50 points)</u></b></H5>\r\n",
        "<p align=\"justify\">2) Based on the result of your classifier from assignment 2A, complete the following:\r\n",
        "<ol>\r\n",
        "<li>Represent the words from the Covid-19 tweets sample data in vector space using the Word2Vec\r\n",
        "approach, and compare the accuracy of your assignment 2A model (which used the tf-idf\r\n",
        "approach) with the new model (10 points)\r\n",
        "</li>\r\n",
        "<li>Using the best model from (a), perform a k-fold (k=10) cross-validation in combination with\r\n",
        "Gridsearch or Randomsearch to fine-tune the performance of your model by varying its\r\n",
        "hyperparameter values (10 points)\r\n",
        "</li>\r\n",
        "<li>Select another classifier and compare the results of your model based on the following criteria:\r\n",
        "Accuracy, Sensitivity and Specificity (10 points)\r\n",
        "</li>\r\n",
        "<li>Carry out a ROC analysis to compare the performance of your model with the selected classifier.\r\n",
        "Plot the ROC graph of the models (10 points)\r\n",
        "</li>\r\n",
        "<li>After tuning your final model, persist using Pickle or Joblib (10 points)</li>\r\n",
        "</ol></p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiJ-fcst0oKj"
      },
      "source": [
        "**Importing required Libraries.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0Uz2Qz4MKpz",
        "outputId": "2f27e581-3c56-4d52-c274-a5b8918a27a6"
      },
      "source": [
        "pip install xgboost"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.7/dist-packages (0.90)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUcDRpRQOm2O",
        "outputId": "03727754-21c9-4477-dd91-16997391dccf"
      },
      "source": [
        "#Import all the important required libraries \r\n",
        "import nltk\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import csv\r\n",
        "import re\r\n",
        "import string\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import pickle\r\n",
        "\r\n",
        "nltk.download('punkt')\r\n",
        "nltk.download('wordnet')\r\n",
        "nltk.download('stopwords')\r\n",
        "\r\n",
        "from nltk.probability import FreqDist\r\n",
        "from nltk.corpus import stopwords\r\n",
        "from nltk.tokenize import word_tokenize\r\n",
        "from nltk.stem import WordNetLemmatizer\r\n",
        "from nltk.classify.scikitlearn import SklearnClassifier\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "from sklearn.naive_bayes import BernoulliNB\r\n",
        "from sklearn.model_selection import cross_val_score\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "from xgboost import XGBClassifier\r\n",
        "from xgboost import XGBRFClassifier\r\n",
        "from sklearn.decomposition import PCA\r\n",
        "from sklearn.cluster import KMeans\r\n",
        "from wordcloud import WordCloud\r\n",
        "from sklearn.model_selection import RandomizedSearchCV\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from functools import reduce\r\n",
        "from sklearn.datasets import load_iris\r\n",
        "from gensim.models import word2vec\r\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, roc_auc_score, roc_curve,auc,plot_roc_curve\r\n",
        "from sklearn.model_selection import StratifiedKFold"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ss_6IEvOqWv"
      },
      "source": [
        "# Import Train and Test data\r\n",
        "covid_test_data = pd.read_csv(\"Covid_test_data.csv\")\r\n",
        "covid_train_data = pd.read_csv(\"Covid_train_data.csv\" , encoding='latin-1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "3Vaz_t55O7sQ",
        "outputId": "3f594360-5a39-4b8b-802c-b38be20b4066"
      },
      "source": [
        "#Display first 10 rows of test data\r\n",
        "covid_test_data.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UserName</th>\n",
              "      <th>ScreenName</th>\n",
              "      <th>Location</th>\n",
              "      <th>TweetAt</th>\n",
              "      <th>OriginalTweet</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>44953</td>\n",
              "      <td>NYC</td>\n",
              "      <td>02-03-2020</td>\n",
              "      <td>TRENDING: New Yorkers encounter empty supermar...</td>\n",
              "      <td>Extremely Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>44954</td>\n",
              "      <td>Seattle, WA</td>\n",
              "      <td>02-03-2020</td>\n",
              "      <td>When I couldn't find hand sanitizer at Fred Me...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>44955</td>\n",
              "      <td>NaN</td>\n",
              "      <td>02-03-2020</td>\n",
              "      <td>Find out how you can protect yourself and love...</td>\n",
              "      <td>Extremely Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>44956</td>\n",
              "      <td>Chicagoland</td>\n",
              "      <td>02-03-2020</td>\n",
              "      <td>#Panic buying hits #NewYork City as anxious sh...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>44957</td>\n",
              "      <td>Melbourne, Victoria</td>\n",
              "      <td>03-03-2020</td>\n",
              "      <td>#toiletpaper #dunnypaper #coronavirus #coronav...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>44958</td>\n",
              "      <td>Los Angeles</td>\n",
              "      <td>03-03-2020</td>\n",
              "      <td>Do you remember the last time you paid $2.99 a...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>44959</td>\n",
              "      <td>NaN</td>\n",
              "      <td>03-03-2020</td>\n",
              "      <td>Voting in the age of #coronavirus = hand sanit...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>44960</td>\n",
              "      <td>Geneva, Switzerland</td>\n",
              "      <td>03-03-2020</td>\n",
              "      <td>@DrTedros \"We cant stop #COVID19 without prot...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>44961</td>\n",
              "      <td>NaN</td>\n",
              "      <td>04-03-2020</td>\n",
              "      <td>HI TWITTER! I am a pharmacist. I sell hand san...</td>\n",
              "      <td>Extremely Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>44962</td>\n",
              "      <td>Dublin, Ireland</td>\n",
              "      <td>04-03-2020</td>\n",
              "      <td>Anyone been in a supermarket over the last few...</td>\n",
              "      <td>Extremely Positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   UserName  ...           Sentiment\n",
              "0         1  ...  Extremely Negative\n",
              "1         2  ...            Positive\n",
              "2         3  ...  Extremely Positive\n",
              "3         4  ...            Negative\n",
              "4         5  ...             Neutral\n",
              "5         6  ...             Neutral\n",
              "6         7  ...            Positive\n",
              "7         8  ...             Neutral\n",
              "8         9  ...  Extremely Negative\n",
              "9        10  ...  Extremely Positive\n",
              "\n",
              "[10 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "Hkz_R4V7O-Oy",
        "outputId": "1d6e392a-8c2b-4ea3-b48e-632d4217a116"
      },
      "source": [
        "#Display first 10 rows of train data \r\n",
        "covid_train_data.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UserName</th>\n",
              "      <th>ScreenName</th>\n",
              "      <th>Location</th>\n",
              "      <th>TweetAt</th>\n",
              "      <th>OriginalTweet</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3799</td>\n",
              "      <td>48751</td>\n",
              "      <td>London</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3800</td>\n",
              "      <td>48752</td>\n",
              "      <td>UK</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>advice Talk to your neighbours family to excha...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3801</td>\n",
              "      <td>48753</td>\n",
              "      <td>Vagabonds</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3802</td>\n",
              "      <td>48754</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>My food stock is not the only one which is emp...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3803</td>\n",
              "      <td>48755</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
              "      <td>Extremely Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3804</td>\n",
              "      <td>48756</td>\n",
              "      <td>ÃT: 36.319708,-82.363649</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>As news of the regionÂs first confirmed COVID...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3805</td>\n",
              "      <td>48757</td>\n",
              "      <td>35.926541,-78.753267</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>Cashier at grocery store was sharing his insig...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>3806</td>\n",
              "      <td>48758</td>\n",
              "      <td>Austria</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>Was at the supermarket today. Didn't buy toile...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>3807</td>\n",
              "      <td>48759</td>\n",
              "      <td>Atlanta, GA USA</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>Due to COVID-19 our retail store and classroom...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>3808</td>\n",
              "      <td>48760</td>\n",
              "      <td>BHAVNAGAR,GUJRAT</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>For corona prevention,we should stop to buy th...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   UserName  ...           Sentiment\n",
              "0      3799  ...             Neutral\n",
              "1      3800  ...            Positive\n",
              "2      3801  ...            Positive\n",
              "3      3802  ...            Positive\n",
              "4      3803  ...  Extremely Negative\n",
              "5      3804  ...            Positive\n",
              "6      3805  ...            Positive\n",
              "7      3806  ...             Neutral\n",
              "8      3807  ...            Positive\n",
              "9      3808  ...            Negative\n",
              "\n",
              "[10 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 603
        },
        "id": "uHCBMZ7bPAa-",
        "outputId": "afae55b8-ae4b-4119-9297-b42a26502df4"
      },
      "source": [
        "#Display data before Preprocessing \r\n",
        "#Display the first five rows of train data to get an idea \r\n",
        "display(covid_train_data.head())\r\n",
        "#Print the summary statistics for train data\r\n",
        "print(covid_train_data.describe())\r\n",
        "#information print about train data\r\n",
        "print(covid_train_data.info())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UserName</th>\n",
              "      <th>ScreenName</th>\n",
              "      <th>Location</th>\n",
              "      <th>TweetAt</th>\n",
              "      <th>OriginalTweet</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3799</td>\n",
              "      <td>48751</td>\n",
              "      <td>London</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3800</td>\n",
              "      <td>48752</td>\n",
              "      <td>UK</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>advice Talk to your neighbours family to excha...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3801</td>\n",
              "      <td>48753</td>\n",
              "      <td>Vagabonds</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3802</td>\n",
              "      <td>48754</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>My food stock is not the only one which is emp...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3803</td>\n",
              "      <td>48755</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
              "      <td>Extremely Negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   UserName  ...           Sentiment\n",
              "0      3799  ...             Neutral\n",
              "1      3800  ...            Positive\n",
              "2      3801  ...            Positive\n",
              "3      3802  ...            Positive\n",
              "4      3803  ...  Extremely Negative\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "           UserName    ScreenName\n",
            "count  41157.000000  41157.000000\n",
            "mean   24377.000000  69329.000000\n",
            "std    11881.146851  11881.146851\n",
            "min     3799.000000  48751.000000\n",
            "25%    14088.000000  59040.000000\n",
            "50%    24377.000000  69329.000000\n",
            "75%    34666.000000  79618.000000\n",
            "max    44955.000000  89907.000000\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 41157 entries, 0 to 41156\n",
            "Data columns (total 6 columns):\n",
            " #   Column         Non-Null Count  Dtype \n",
            "---  ------         --------------  ----- \n",
            " 0   UserName       41157 non-null  int64 \n",
            " 1   ScreenName     41157 non-null  int64 \n",
            " 2   Location       32567 non-null  object\n",
            " 3   TweetAt        41157 non-null  object\n",
            " 4   OriginalTweet  41157 non-null  object\n",
            " 5   Sentiment      41157 non-null  object\n",
            "dtypes: int64(2), object(4)\n",
            "memory usage: 1.9+ MB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2X4wSeOtPFc6",
        "outputId": "79c7b028-93ab-48e1-ec52-71c7ef0d4098"
      },
      "source": [
        "#Removing first 2 unnecessary columns\r\n",
        "covid_train_data.drop(columns=[\"UserName\", \"ScreenName\"], axis=1, inplace=True)\r\n",
        "#Removing duplicated rows\r\n",
        "covid_train_data.drop_duplicates(inplace=True)\r\n",
        "#Changing datatype\r\n",
        "covid_train_data[\"TweetAt\"] = pd.to_datetime(covid_train_data[\"TweetAt\"])\r\n",
        "# Print the information of Train data\r\n",
        "print(covid_train_data.info())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 41157 entries, 0 to 41156\n",
            "Data columns (total 4 columns):\n",
            " #   Column         Non-Null Count  Dtype         \n",
            "---  ------         --------------  -----         \n",
            " 0   Location       32567 non-null  object        \n",
            " 1   TweetAt        41157 non-null  datetime64[ns]\n",
            " 2   OriginalTweet  41157 non-null  object        \n",
            " 3   Sentiment      41157 non-null  object        \n",
            "dtypes: datetime64[ns](1), object(3)\n",
            "memory usage: 1.6+ MB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "VucCWWk7PJW_",
        "outputId": "48f5878a-fd1a-49b7-fcd1-56a188fa6423"
      },
      "source": [
        "#Function for Preprocessing the Train data\r\n",
        "def process_tweets(tweet):\r\n",
        "    \r\n",
        "    # Remove links\r\n",
        "    tweet = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', tweet, flags=re.MULTILINE)\r\n",
        "    \r\n",
        "    # Remove mentions and hashtag\r\n",
        "    tweet = re.sub(r'\\@\\w+|\\#','', tweet)\r\n",
        "    \r\n",
        "    # Tokenize the words\r\n",
        "    tokenized = word_tokenize(tweet)\r\n",
        "\r\n",
        "    # Remove the stop words\r\n",
        "    tokenized = [token for token in tokenized if token not in stopwords.words(\"english\")] \r\n",
        "\r\n",
        "    # Lemmatize the words\r\n",
        "    lemmatizer = WordNetLemmatizer()\r\n",
        "    tokenized = [lemmatizer.lemmatize(token, pos='a') for token in tokenized]\r\n",
        "\r\n",
        "    # Remove non-alphabetic characters and keep the words contains three or more letters\r\n",
        "    tokenized = [token for token in tokenized if token.isalpha() and len(token)>2]\r\n",
        "    \r\n",
        "    return tokenized\r\n",
        "    \r\n",
        "# Call the function and store the result into a new column\r\n",
        "covid_train_data[\"Processed\"] = covid_train_data[\"OriginalTweet\"].str.lower().apply(process_tweets)\r\n",
        "\r\n",
        "# Print the first ten rows of Processed\r\n",
        "covid_train_data.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Location</th>\n",
              "      <th>TweetAt</th>\n",
              "      <th>OriginalTweet</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Processed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>London</td>\n",
              "      <td>2020-03-16</td>\n",
              "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>UK</td>\n",
              "      <td>2020-03-16</td>\n",
              "      <td>advice Talk to your neighbours family to excha...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>[advice, talk, neighbours, family, exchange, p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Vagabonds</td>\n",
              "      <td>2020-03-16</td>\n",
              "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>[coronavirus, australia, woolworths, give, eld...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>2020-03-16</td>\n",
              "      <td>My food stock is not the only one which is emp...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>[food, stock, one, empty, please, panic, enoug...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>2020-03-16</td>\n",
              "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
              "      <td>Extremely Negative</td>\n",
              "      <td>[ready, supermarket, outbreak, paranoid, food,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ÃT: 36.319708,-82.363649</td>\n",
              "      <td>2020-03-16</td>\n",
              "      <td>As news of the regionÂs first confirmed COVID...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>[news, first, confirmed, case, came, sullivan,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>35.926541,-78.753267</td>\n",
              "      <td>2020-03-16</td>\n",
              "      <td>Cashier at grocery store was sharing his insig...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>[cashier, grocery, store, sharing, insights, p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Austria</td>\n",
              "      <td>2020-03-16</td>\n",
              "      <td>Was at the supermarket today. Didn't buy toile...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>[supermarket, today, buy, toilet, paper, rebel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Atlanta, GA USA</td>\n",
              "      <td>2020-03-16</td>\n",
              "      <td>Due to COVID-19 our retail store and classroom...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>[due, retail, store, classroom, atlanta, open,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>BHAVNAGAR,GUJRAT</td>\n",
              "      <td>2020-03-16</td>\n",
              "      <td>For corona prevention,we should stop to buy th...</td>\n",
              "      <td>Negative</td>\n",
              "      <td>[corona, prevention, stop, buy, things, cash, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    Location  ...                                          Processed\n",
              "0                     London  ...                                                 []\n",
              "1                         UK  ...  [advice, talk, neighbours, family, exchange, p...\n",
              "2                  Vagabonds  ...  [coronavirus, australia, woolworths, give, eld...\n",
              "3                        NaN  ...  [food, stock, one, empty, please, panic, enoug...\n",
              "4                        NaN  ...  [ready, supermarket, outbreak, paranoid, food,...\n",
              "5  ÃT: 36.319708,-82.363649  ...  [news, first, confirmed, case, came, sullivan,...\n",
              "6       35.926541,-78.753267  ...  [cashier, grocery, store, sharing, insights, p...\n",
              "7                    Austria  ...  [supermarket, today, buy, toilet, paper, rebel...\n",
              "8            Atlanta, GA USA  ...  [due, retail, store, classroom, atlanta, open,...\n",
              "9           BHAVNAGAR,GUJRAT  ...  [corona, prevention, stop, buy, things, cash, ...\n",
              "\n",
              "[10 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "BzwdULhUPNap",
        "outputId": "9c6d921b-e13b-4598-8cee-15ccd77e5aff"
      },
      "source": [
        "# Get the tweet lengths for train data\r\n",
        "covid_train_data[\"Length\"] = covid_train_data[\"OriginalTweet\"].str.len()\r\n",
        "# Get the number of words in tweets train data\r\n",
        "covid_train_data[\"Words\"] = covid_train_data[\"OriginalTweet\"].str.split().str.len()\r\n",
        "# Display the new columns of train data\r\n",
        "display(covid_train_data[[\"Length\", \"Words\"]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Length</th>\n",
              "      <th>Words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>111</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>237</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>131</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>306</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>310</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41152</th>\n",
              "      <td>102</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41153</th>\n",
              "      <td>138</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41154</th>\n",
              "      <td>136</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41155</th>\n",
              "      <td>111</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41156</th>\n",
              "      <td>255</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>41157 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Length  Words\n",
              "0         111      8\n",
              "1         237     38\n",
              "2         131     14\n",
              "3         306     42\n",
              "4         310     40\n",
              "...       ...    ...\n",
              "41152     102     12\n",
              "41153     138     23\n",
              "41154     136     18\n",
              "41155     111     18\n",
              "41156     255     46\n",
              "\n",
              "[41157 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEm_8wS-PUjF"
      },
      "source": [
        "# Fill the missing values with unknown tag in train data\r\n",
        "covid_train_data[\"Location\"].fillna(\"unknown\", inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "O1V2mePyPY07",
        "outputId": "59bf23e8-ec87-4639-f5a3-16eb6153ba26"
      },
      "source": [
        "#function for preprocessing Test data in order to use further in calculating accuracy\r\n",
        "def process_tweets(tweet):\r\n",
        "    \r\n",
        "    # Remove links\r\n",
        "    tweet = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', tweet, flags=re.MULTILINE)\r\n",
        "    \r\n",
        "    # Remove mentions and hashtag\r\n",
        "    tweet = re.sub(r'\\@\\w+|\\#','', tweet)\r\n",
        "    \r\n",
        "    # Tokenize the words\r\n",
        "    tokenized = word_tokenize(tweet)\r\n",
        "\r\n",
        "    # Remove the stop words\r\n",
        "    tokenized = [token for token in tokenized if token not in stopwords.words(\"english\")] \r\n",
        "\r\n",
        "    # Lemmatize the words\r\n",
        "    lemmatizer = WordNetLemmatizer()\r\n",
        "    tokenized = [lemmatizer.lemmatize(token, pos='a') for token in tokenized]\r\n",
        "\r\n",
        "    # Remove non-alphabetic characters and keep the words contains three or more letters\r\n",
        "    tokenized = [token for token in tokenized if token.isalpha() and len(token)>2]\r\n",
        "    \r\n",
        "    return tokenized\r\n",
        "    \r\n",
        "# Call the function and store the result into a new column\r\n",
        "covid_test_data[\"Processed\"] = covid_test_data[\"OriginalTweet\"].str.lower().apply(process_tweets)\r\n",
        "\r\n",
        "# Print the first ten rows of Processed\r\n",
        "covid_test_data.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UserName</th>\n",
              "      <th>ScreenName</th>\n",
              "      <th>Location</th>\n",
              "      <th>TweetAt</th>\n",
              "      <th>OriginalTweet</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Processed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>44953</td>\n",
              "      <td>NYC</td>\n",
              "      <td>02-03-2020</td>\n",
              "      <td>TRENDING: New Yorkers encounter empty supermar...</td>\n",
              "      <td>Extremely Negative</td>\n",
              "      <td>[trending, new, yorkers, encounter, empty, sup...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>44954</td>\n",
              "      <td>Seattle, WA</td>\n",
              "      <td>02-03-2020</td>\n",
              "      <td>When I couldn't find hand sanitizer at Fred Me...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>[could, find, hand, sanitizer, fred, meyer, tu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>44955</td>\n",
              "      <td>NaN</td>\n",
              "      <td>02-03-2020</td>\n",
              "      <td>Find out how you can protect yourself and love...</td>\n",
              "      <td>Extremely Positive</td>\n",
              "      <td>[find, protect, loved, ones, coronavirus]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>44956</td>\n",
              "      <td>Chicagoland</td>\n",
              "      <td>02-03-2020</td>\n",
              "      <td>#Panic buying hits #NewYork City as anxious sh...</td>\n",
              "      <td>Negative</td>\n",
              "      <td>[panic, buying, hits, newyork, city, anxious, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>44957</td>\n",
              "      <td>Melbourne, Victoria</td>\n",
              "      <td>03-03-2020</td>\n",
              "      <td>#toiletpaper #dunnypaper #coronavirus #coronav...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>[toiletpaper, dunnypaper, coronavirus, coronav...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>44958</td>\n",
              "      <td>Los Angeles</td>\n",
              "      <td>03-03-2020</td>\n",
              "      <td>Do you remember the last time you paid $2.99 a...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>[remember, last, time, paid, gallon, regular, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>44959</td>\n",
              "      <td>NaN</td>\n",
              "      <td>03-03-2020</td>\n",
              "      <td>Voting in the age of #coronavirus = hand sanit...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>[voting, age, coronavirus, hand, sanitizer, su...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>44960</td>\n",
              "      <td>Geneva, Switzerland</td>\n",
              "      <td>03-03-2020</td>\n",
              "      <td>@DrTedros \"We cant stop #COVID19 without prot...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>[stop, without, protecting, healthworkers, pri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>44961</td>\n",
              "      <td>NaN</td>\n",
              "      <td>04-03-2020</td>\n",
              "      <td>HI TWITTER! I am a pharmacist. I sell hand san...</td>\n",
              "      <td>Extremely Negative</td>\n",
              "      <td>[twitter, pharmacist, sell, hand, sanitizer, l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>44962</td>\n",
              "      <td>Dublin, Ireland</td>\n",
              "      <td>04-03-2020</td>\n",
              "      <td>Anyone been in a supermarket over the last few...</td>\n",
              "      <td>Extremely Positive</td>\n",
              "      <td>[anyone, supermarket, last, days, went, normal...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   UserName  ...                                          Processed\n",
              "0         1  ...  [trending, new, yorkers, encounter, empty, sup...\n",
              "1         2  ...  [could, find, hand, sanitizer, fred, meyer, tu...\n",
              "2         3  ...          [find, protect, loved, ones, coronavirus]\n",
              "3         4  ...  [panic, buying, hits, newyork, city, anxious, ...\n",
              "4         5  ...  [toiletpaper, dunnypaper, coronavirus, coronav...\n",
              "5         6  ...  [remember, last, time, paid, gallon, regular, ...\n",
              "6         7  ...  [voting, age, coronavirus, hand, sanitizer, su...\n",
              "7         8  ...  [stop, without, protecting, healthworkers, pri...\n",
              "8         9  ...  [twitter, pharmacist, sell, hand, sanitizer, l...\n",
              "9        10  ...  [anyone, supermarket, last, days, went, normal...\n",
              "\n",
              "[10 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "6lY2BS-tPcUd",
        "outputId": "6e7646f5-4c0a-43a9-cc63-2b5a6876e408"
      },
      "source": [
        "# Get the tweet lengths of test data\r\n",
        "covid_test_data[\"Length\"] = covid_test_data[\"OriginalTweet\"].str.len()\r\n",
        "# Get the number of words in tweets of test data\r\n",
        "covid_test_data[\"Words\"] = covid_test_data[\"OriginalTweet\"].str.split().str.len()\r\n",
        "# Display the new columns of test data\r\n",
        "display(covid_test_data[[\"Length\", \"Words\"]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Length</th>\n",
              "      <th>Words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>228</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>193</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>73</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>318</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>252</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3793</th>\n",
              "      <td>127</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3794</th>\n",
              "      <td>213</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3795</th>\n",
              "      <td>185</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3796</th>\n",
              "      <td>174</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3797</th>\n",
              "      <td>254</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3798 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Length  Words\n",
              "0        228     23\n",
              "1        193     30\n",
              "2         73     13\n",
              "3        318     37\n",
              "4        252     26\n",
              "...      ...    ...\n",
              "3793     127     18\n",
              "3794     213     34\n",
              "3795     185     26\n",
              "3796     174     29\n",
              "3797     254     33\n",
              "\n",
              "[3798 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkCxJP_o04QO"
      },
      "source": [
        "**TF-IDF for train data (Part of Assignment 2)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "8znE3ZaUPfU2",
        "outputId": "1dd4f32a-2075-4deb-c791-d9abbe729f52"
      },
      "source": [
        "# Initialize a Tf-idf Vectorizer\r\n",
        "vectorizer = TfidfVectorizer(max_features=100)\r\n",
        "# Fit and transform the vectorizer\r\n",
        "tfidf_matrix = vectorizer.fit_transform([' '.join(l) for l in covid_train_data[\"Processed\"]])\r\n",
        "# Let's see what we have\r\n",
        "display(tfidf_matrix)\r\n",
        "# Create a DataFrame for tf-idf vectors and display the first rows\r\n",
        "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns= vectorizer.get_feature_names())\r\n",
        "display(tfidf_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<41157x100 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 186001 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>also</th>\n",
              "      <th>amid</th>\n",
              "      <th>amp</th>\n",
              "      <th>back</th>\n",
              "      <th>business</th>\n",
              "      <th>buy</th>\n",
              "      <th>buying</th>\n",
              "      <th>consumer</th>\n",
              "      <th>coronavirus</th>\n",
              "      <th>could</th>\n",
              "      <th>covid</th>\n",
              "      <th>crisis</th>\n",
              "      <th>customers</th>\n",
              "      <th>day</th>\n",
              "      <th>delivery</th>\n",
              "      <th>demand</th>\n",
              "      <th>due</th>\n",
              "      <th>employees</th>\n",
              "      <th>essential</th>\n",
              "      <th>even</th>\n",
              "      <th>every</th>\n",
              "      <th>everyone</th>\n",
              "      <th>first</th>\n",
              "      <th>food</th>\n",
              "      <th>get</th>\n",
              "      <th>going</th>\n",
              "      <th>good</th>\n",
              "      <th>government</th>\n",
              "      <th>grocery</th>\n",
              "      <th>hand</th>\n",
              "      <th>health</th>\n",
              "      <th>help</th>\n",
              "      <th>high</th>\n",
              "      <th>home</th>\n",
              "      <th>impact</th>\n",
              "      <th>items</th>\n",
              "      <th>keep</th>\n",
              "      <th>know</th>\n",
              "      <th>like</th>\n",
              "      <th>local</th>\n",
              "      <th>...</th>\n",
              "      <th>prices</th>\n",
              "      <th>products</th>\n",
              "      <th>retail</th>\n",
              "      <th>right</th>\n",
              "      <th>safe</th>\n",
              "      <th>sanitizer</th>\n",
              "      <th>see</th>\n",
              "      <th>shelves</th>\n",
              "      <th>shop</th>\n",
              "      <th>shopping</th>\n",
              "      <th>social</th>\n",
              "      <th>socialdistancing</th>\n",
              "      <th>spread</th>\n",
              "      <th>staff</th>\n",
              "      <th>stay</th>\n",
              "      <th>still</th>\n",
              "      <th>stock</th>\n",
              "      <th>stop</th>\n",
              "      <th>store</th>\n",
              "      <th>stores</th>\n",
              "      <th>supermarket</th>\n",
              "      <th>supplies</th>\n",
              "      <th>supply</th>\n",
              "      <th>take</th>\n",
              "      <th>thank</th>\n",
              "      <th>think</th>\n",
              "      <th>time</th>\n",
              "      <th>today</th>\n",
              "      <th>toilet</th>\n",
              "      <th>toiletpaper</th>\n",
              "      <th>use</th>\n",
              "      <th>via</th>\n",
              "      <th>virus</th>\n",
              "      <th>way</th>\n",
              "      <th>week</th>\n",
              "      <th>work</th>\n",
              "      <th>workers</th>\n",
              "      <th>working</th>\n",
              "      <th>world</th>\n",
              "      <th>would</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.497447</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.702164</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.617436</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.243451</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.453185</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.115334</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.287786</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.358077</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.291483</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.551151</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.250835</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.282739</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.197031</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.305863</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.428518</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.292708</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41152</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.549792</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.503874</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.344182</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41153</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.558534</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.829481</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41154</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.190497</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.409194</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.463867</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.442128</td>\n",
              "      <td>0.428688</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41155</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.554381</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.598742</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.578075</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41156</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.423872</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.279045</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.502163</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>41157 rows × 100 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       also      amid  amp  back  ...  workers  working  world  would\n",
              "0       0.0  0.000000  0.0   0.0  ...      0.0      0.0    0.0    0.0\n",
              "1       0.0  0.000000  0.0   0.0  ...      0.0      0.0    0.0    0.0\n",
              "2       0.0  0.617436  0.0   0.0  ...      0.0      0.0    0.0    0.0\n",
              "3       0.0  0.000000  0.0   0.0  ...      0.0      0.0    0.0    0.0\n",
              "4       0.0  0.000000  0.0   0.0  ...      0.0      0.0    0.0    0.0\n",
              "...     ...       ...  ...   ...  ...      ...      ...    ...    ...\n",
              "41152   0.0  0.000000  0.0   0.0  ...      0.0      0.0    0.0    0.0\n",
              "41153   0.0  0.000000  0.0   0.0  ...      0.0      0.0    0.0    0.0\n",
              "41154   0.0  0.000000  0.0   0.0  ...      0.0      0.0    0.0    0.0\n",
              "41155   0.0  0.000000  0.0   0.0  ...      0.0      0.0    0.0    0.0\n",
              "41156   0.0  0.000000  0.0   0.0  ...      0.0      0.0    0.0    0.0\n",
              "\n",
              "[41157 rows x 100 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "-preHHhwPpbs",
        "outputId": "3fb160b3-f48c-4658-9792-fbb2a71d0c4d"
      },
      "source": [
        "# Encode the labels for train data\r\n",
        "le = LabelEncoder()\r\n",
        "covid_train_data[\"Label_enc\"] = le.fit_transform(covid_train_data[\"Sentiment\"])\r\n",
        "# Display the encoded labels of train data\r\n",
        "display(covid_train_data[[\"Label_enc\"]].head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label_enc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Label_enc\n",
              "0          3\n",
              "1          4\n",
              "2          4\n",
              "3          4\n",
              "4          0"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "PGafDon4PsNu",
        "outputId": "af2b8aa5-82d2-4e0b-adf2-3da96e109fbe"
      },
      "source": [
        "# Encode the labels for test data \r\n",
        "le = LabelEncoder()\r\n",
        "covid_test_data[\"Label_enc\"] = le.fit_transform(covid_test_data[\"Sentiment\"])\r\n",
        "# Display the encoded labels of test data\r\n",
        "display(covid_test_data[[\"Label_enc\"]].head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label_enc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Label_enc\n",
              "0          0\n",
              "1          4\n",
              "2          1\n",
              "3          2\n",
              "4          3"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m41qDqbkP01r"
      },
      "source": [
        "# Select the features and the target and split train and test\r\n",
        "X_train = covid_train_data['Processed']\r\n",
        "Y_train = covid_train_data[\"Label_enc\"]\r\n",
        "X_test = covid_test_data['Processed']\r\n",
        "Y_test = covid_test_data[\"Label_enc\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2Izk0NvP5QA"
      },
      "source": [
        "# Create the tf-idf vectorizer\r\n",
        "model_vectorizer = TfidfVectorizer()\r\n",
        "# First fit the vectorizer with our training set\r\n",
        "tfidf_train = vectorizer.fit_transform([' '.join(l) for l in X_train])\r\n",
        "# Now we can fit our test data with the same vectorizer\r\n",
        "tfidf_test = vectorizer.transform([' '.join(l) for l in X_test])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJYghLCu8z1M",
        "outputId": "1ac32098-2792-4b94-945f-f5bb34e3d858"
      },
      "source": [
        "def generate_rf(X_train, y_train, X_test, y_test):\r\n",
        "    rf = RandomForestClassifier(n_estimators=5, min_samples_leaf=3)\r\n",
        "    rf.fit(X_train, y_train)\r\n",
        "    print (\"rf score \", rf.score(X_test, y_test))\r\n",
        "    return rf\r\n",
        "\r\n",
        "def combine_rfs(rf_a, rf_b):\r\n",
        "    rf_a.estimators_ += rf_b.estimators_\r\n",
        "    rf_a.n_estimators = len(rf_a.estimators_)\r\n",
        "    return rf_a\r\n",
        "\r\n",
        "\r\n",
        "# in the line below, we create 10 random forest classifier models\r\n",
        "rfs_tfidf = [generate_rf(tfidf_train, Y_train, tfidf_test, Y_test)]\r\n",
        "# in this step below, we combine the list of random forest models into one giant model\r\n",
        "rf_tfidf_combined = reduce(combine_rfs, rfs_tfidf)\r\n",
        "# the combined model scores better than most of the component models\r\n",
        "print (\"rf combined score\", rf_tfidf_combined.score(tfidf_test, Y_test))\r\n",
        "# Print the accuracy score\r\n",
        "best_accuracy = cross_val_score(rf_tfidf_combined, tfidf_test, Y_test, cv=10, scoring='accuracy').max()\r\n",
        "print(\"Accuracy:\",best_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rf score  0.35624012638230645\n",
            "rf combined score 0.35624012638230645\n",
            "Accuracy: 0.3562005277044855\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_R1pYRB1O2N"
      },
      "source": [
        "**1. Represent the words from the Covid-19 tweets sample data in vector space using the Word2Vec approach, and compare the accuracy of your assignment 2A model (which used the tf-idf approach) with the new model (10 points)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QgG-tflQGpQ"
      },
      "source": [
        "# Word Embeddings\r\n",
        "wpt = nltk.WordPunctTokenizer()\r\n",
        "tokenized_corpus = [wpt.tokenize(document) for document in  X_train.str.join(' ')]\r\n",
        "\r\n",
        "# Set values for various parameters\r\n",
        "feature_size = 100    # Word vector dimensionality, i.e., number of dimension we wish to represent the word \r\n",
        "window_context = 10  # Context window size                                                                                    \r\n",
        "min_word_count = 1   # Minimum word count, i.e., words > this are going to be included in the model                        \r\n",
        "sample = 1e-3        # Downsample setting for frequent words\r\n",
        "\r\n",
        "w2v_model = word2vec.Word2Vec(tokenized_corpus, size=feature_size, \r\n",
        "                              window=window_context, min_count = min_word_count,\r\n",
        "                              sample=sample)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VqFU5F1QmDT",
        "outputId": "b13483aa-81fe-4fca-bc57-37b21f5b7495"
      },
      "source": [
        "def average_word_vectors(words, model, vocabulary, num_features):\r\n",
        "    \r\n",
        "    feature_vector = np.zeros((num_features,),dtype=\"float64\")\r\n",
        "    nwords = 0.\r\n",
        "    \r\n",
        "    for word in words:\r\n",
        "        if word in vocabulary: \r\n",
        "            nwords = nwords + 1.\r\n",
        "            feature_vector = np.add(feature_vector, model[word])\r\n",
        "    \r\n",
        "    if nwords:\r\n",
        "        feature_vector = np.divide(feature_vector, nwords)\r\n",
        "        \r\n",
        "    return feature_vector\r\n",
        "   \r\n",
        "def averaged_word_vectorizer(corpus, model, num_features):\r\n",
        "    vocabulary = set(model.wv.index2word)\r\n",
        "    features = [average_word_vectors(tokenized_sentence, model, vocabulary, num_features)\r\n",
        "                    for tokenized_sentence in corpus]\r\n",
        "    return np.array(features)\r\n",
        "\r\n",
        "\r\n",
        "w2v_feature_array = averaged_word_vectorizer(corpus=tokenized_corpus, model=w2v_model,\r\n",
        "                                             num_features=feature_size)\r\n",
        "w2v_train = pd.DataFrame(w2v_feature_array)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIJlpUaWuwJ8"
      },
      "source": [
        "# Word Embeddings\r\n",
        "wpt = nltk.WordPunctTokenizer()\r\n",
        "tokenized_corpus = [wpt.tokenize(document) for document in  X_test.str.join(' ')]\r\n",
        "\r\n",
        "# Set values for various parameters\r\n",
        "feature_size = 100    # Word vector dimensionality, i.e., number of dimension we wish to represent the word \r\n",
        "window_context = 10  # Context window size                                                                                    \r\n",
        "min_word_count = 1   # Minimum word count, i.e., words > this are going to be included in the model                        \r\n",
        "sample = 1e-3        # Downsample setting for frequent words\r\n",
        "\r\n",
        "w2v_model = word2vec.Word2Vec(tokenized_corpus, size=feature_size, \r\n",
        "                              window=window_context, min_count = min_word_count,\r\n",
        "                              sample=sample)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgT95sRyuyuP",
        "outputId": "14394d0f-a954-4e90-f385-6b49f5b35bfa"
      },
      "source": [
        "def average_word_vectors(words, model, vocabulary, num_features):\r\n",
        "    \r\n",
        "    feature_vector = np.zeros((num_features,),dtype=\"float64\")\r\n",
        "    nwords = 0.\r\n",
        "    \r\n",
        "    for word in words:\r\n",
        "        if word in vocabulary: \r\n",
        "            nwords = nwords + 1.\r\n",
        "            feature_vector = np.add(feature_vector, model[word])\r\n",
        "    \r\n",
        "    if nwords:\r\n",
        "        feature_vector = np.divide(feature_vector, nwords)\r\n",
        "        \r\n",
        "    return feature_vector\r\n",
        "   \r\n",
        "def averaged_word_vectorizer(corpus, model, num_features):\r\n",
        "    vocabulary = set(model.wv.index2word)\r\n",
        "    features = [average_word_vectors(tokenized_sentence, model, vocabulary, num_features)\r\n",
        "                    for tokenized_sentence in corpus]\r\n",
        "    return np.array(features)\r\n",
        "\r\n",
        "\r\n",
        "w2v_feature_array = averaged_word_vectorizer(corpus=tokenized_corpus, model=w2v_model,\r\n",
        "                                             num_features=feature_size)\r\n",
        "w2v_test = pd.DataFrame(w2v_feature_array)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkoAmc3f9771",
        "outputId": "f9c2ae57-8e9b-40f0-8c55-5bbb6d8c838c"
      },
      "source": [
        "def generate_rf(X_train, y_train, X_test, y_test):\r\n",
        "    rf = RandomForestClassifier(n_estimators=5, min_samples_leaf=3)\r\n",
        "    rf.fit(X_train, y_train)\r\n",
        "    print (\"rf score \", rf.score(X_test, y_test))\r\n",
        "    return rf\r\n",
        "\r\n",
        "def combine_rfs(rf_a, rf_b):\r\n",
        "    rf_a.estimators_ += rf_b.estimators_\r\n",
        "    rf_a.n_estimators = len(rf_a.estimators_)\r\n",
        "    return rf_a\r\n",
        "\r\n",
        "\r\n",
        "# in the line below, we create 10 random forest classifier models\r\n",
        "rfs_w2v = [generate_rf(w2v_train, Y_train, w2v_test, Y_test)]\r\n",
        "# in this step below, we combine the list of random forest models into one giant model\r\n",
        "rf_w2v_combined = reduce(combine_rfs, rfs_w2v)\r\n",
        "# the combined model scores better than most of the component models\r\n",
        "print (\"rf combined score\", rf_w2v_combined.score(w2v_test, Y_test))\r\n",
        "# Print the accuracy score\r\n",
        "best_accuracy = cross_val_score(rf_w2v_combined, w2v_test, Y_test, cv=10, scoring='accuracy').max()\r\n",
        "print(\"Accuracy:\",best_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rf score  0.27593470247498686\n",
            "rf combined score 0.27593470247498686\n",
            "Accuracy: 0.3034300791556728\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlOjdqx_1eOb"
      },
      "source": [
        "**2. Using the best model from (a), perform a k-fold (k=10) cross-validation in combination with Gridsearch or Randomsearch to fine-tune the performance of your model by varying its hyperparameter values (10 points)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLZrdmxO1qfB"
      },
      "source": [
        "As we clearly see that the accuracy for TF-IDF using random forest classifier is better than the accuracy for Word2Vec using random forest classifer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXcutH4WzEhx"
      },
      "source": [
        "def performance(ypred, yactl):\r\n",
        "    print(f'F1-score  : {f1_score(yactl, ypred, average=\"macro\")}')\r\n",
        "    print(f'Accuracy  : {accuracy_score(yactl, ypred)}')\r\n",
        "    print(f'Precision : {precision_score(yactl, ypred, average=\"macro\")}')\r\n",
        "    print(f'Recall    : {recall_score(yactl, ypred, average=\"macro\")}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVlkhpNyzEdd",
        "outputId": "66b9d78c-71f9-4ae3-9761-30385e90dc45"
      },
      "source": [
        "rfc = RandomForestClassifier(n_jobs=-1)\r\n",
        "n_estimators = [150,200,300]\r\n",
        "# Number of features to consider at every split\r\n",
        "max_features = ['auto', 'sqrt']\r\n",
        "# Maximum number of levels in tree\r\n",
        "max_depth = [10,20,40]\r\n",
        "max_depth.append(None)\r\n",
        "# Minimum number of samples required to split a node\r\n",
        "min_samples_split = [2, 5, 10]\r\n",
        "# Minimum number of samples required at each leaf node\r\n",
        "min_samples_leaf = [1, 2, 4]\r\n",
        "# Method of selecting samples for training each tree\r\n",
        "bootstrap = [True, False]# Create the random grid\r\n",
        "random_grid = {'n_estimators': n_estimators,\r\n",
        "               'max_features': max_features,\r\n",
        "               'max_depth': max_depth,\r\n",
        "               'min_samples_split': min_samples_split,\r\n",
        "               'min_samples_leaf': min_samples_leaf,\r\n",
        "               'bootstrap': bootstrap}\r\n",
        "print(random_grid)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'n_estimators': [150, 200, 300], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 40, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URIGvVu_zEcA",
        "outputId": "239c9ad6-41ec-45ef-81fd-51262ae66072"
      },
      "source": [
        "rf_random = RandomizedSearchCV(estimator=rfc, param_distributions=random_grid, cv=10, verbose=2, random_state=42, n_jobs=-1)\r\n",
        "# Fit the random search model\r\n",
        "rf_random.fit(tfidf_df, Y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  7.2min\n",
            "/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 27.3min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=10, error_score=nan,\n",
              "                   estimator=RandomForestClassifier(bootstrap=True,\n",
              "                                                    ccp_alpha=0.0,\n",
              "                                                    class_weight=None,\n",
              "                                                    criterion='gini',\n",
              "                                                    max_depth=None,\n",
              "                                                    max_features='auto',\n",
              "                                                    max_leaf_nodes=None,\n",
              "                                                    max_samples=None,\n",
              "                                                    min_impurity_decrease=0.0,\n",
              "                                                    min_impurity_split=None,\n",
              "                                                    min_samples_leaf=1,\n",
              "                                                    min_samples_split=2,\n",
              "                                                    min_weight_fraction_leaf=0.0,\n",
              "                                                    n_estimators=100, n_job...\n",
              "                                                    verbose=0,\n",
              "                                                    warm_start=False),\n",
              "                   iid='deprecated', n_iter=10, n_jobs=-1,\n",
              "                   param_distributions={'bootstrap': [True, False],\n",
              "                                        'max_depth': [10, 20, 40, None],\n",
              "                                        'max_features': ['auto', 'sqrt'],\n",
              "                                        'min_samples_leaf': [1, 2, 4],\n",
              "                                        'min_samples_split': [2, 5, 10],\n",
              "                                        'n_estimators': [150, 200, 300]},\n",
              "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
              "                   return_train_score=False, scoring=None, verbose=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZN8LWzF6zEXw",
        "outputId": "df94e3bb-16e4-41bf-eae8-e11f8edd0e64"
      },
      "source": [
        "#Finding best parameters \r\n",
        "rf_random.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bootstrap': True,\n",
              " 'max_depth': None,\n",
              " 'max_features': 'auto',\n",
              " 'min_samples_leaf': 4,\n",
              " 'min_samples_split': 2,\n",
              " 'n_estimators': 150}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBI5i2EhzEWf"
      },
      "source": [
        "#Initializing best parameters \r\n",
        "rfc = RandomForestClassifier(n_estimators=150,\r\n",
        "                             min_samples_split= 2,\r\n",
        "                             min_samples_leaf= 4,\r\n",
        "                             max_features= 'auto',\r\n",
        "                             max_depth= None,\r\n",
        "                             bootstrap= True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6OdPtq0zEOy",
        "outputId": "545c0522-faa0-46bf-fcf9-af2638be036f"
      },
      "source": [
        "rfc.fit(tfidf_train, Y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=4, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=150,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONtX_H_lcZLt"
      },
      "source": [
        "pred = rfc.predict(tfidf_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3O6oimLcZEo"
      },
      "source": [
        "pred_prob = rfc.predict_proba(tfidf_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHBRV7Bai7HF",
        "outputId": "59c51f57-419b-4cd6-db59-849d0067ace3"
      },
      "source": [
        "performance(pred, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1-score  : 0.37581781774847356\n",
            "Accuracy  : 0.37783043707214325\n",
            "Precision : 0.4094355001382114\n",
            "Recall    : 0.37043085589238967\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSKOg6u2JxOI",
        "outputId": "e3872b3c-c2d6-4d1f-9f5e-52758f4ce664"
      },
      "source": [
        "# Print the Confusion Matrix\r\n",
        "cm = confusion_matrix(Y_test, pred)\r\n",
        "print(\"Confusion Matrix\\n\")\r\n",
        "print(cm)\r\n",
        "# Print the Classification Report\r\n",
        "cr = classification_report(Y_test, pred)\r\n",
        "print(\"\\n\\nClassification Report\\n\")\r\n",
        "print(cr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix\n",
            "\n",
            "[[157  20 202  74 139]\n",
            " [ 25 184  89  71 230]\n",
            " [101  44 378 193 325]\n",
            " [ 14   9 135 287 174]\n",
            " [ 35 104 205 174 429]]\n",
            "\n",
            "\n",
            "Classification Report\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.27      0.34       592\n",
            "           1       0.51      0.31      0.38       599\n",
            "           2       0.37      0.36      0.37      1041\n",
            "           3       0.36      0.46      0.40       619\n",
            "           4       0.33      0.45      0.38       947\n",
            "\n",
            "    accuracy                           0.38      3798\n",
            "   macro avg       0.41      0.37      0.38      3798\n",
            "weighted avg       0.40      0.38      0.38      3798\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbM3Qb1_Ks5S"
      },
      "source": [
        "def confusion_metrics (conf_matrix):\r\n",
        "# save confusion matrix and slice into four pieces\r\n",
        "    TP = conf_matrix[1][1]\r\n",
        "    TN = conf_matrix[0][0]\r\n",
        "    FP = conf_matrix[0][1]\r\n",
        "    FN = conf_matrix[1][0]\r\n",
        "    print('True Positives:', TP)\r\n",
        "    print('True Negatives:', TN)\r\n",
        "    print('False Positives:', FP)\r\n",
        "    print('False Negatives:', FN)\r\n",
        "    \r\n",
        "    # calculate the sensitivity\r\n",
        "    conf_sensitivity = (TP / float(TP + FN))\r\n",
        "    # calculate the specificity\r\n",
        "    conf_specificity = (TN / float(TN + FP))\r\n",
        "\r\n",
        "    print(f'Sensitivity: {round(conf_sensitivity,2)}') \r\n",
        "    print(f'Specificity: {round(conf_specificity,2)}') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_MgocmNLRTZ",
        "outputId": "c93f3c1b-3432-4832-9a65-f87d221e6081"
      },
      "source": [
        "confusion_metrics(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True Positives: 184\n",
            "True Negatives: 157\n",
            "False Positives: 20\n",
            "False Negatives: 25\n",
            "Sensitivity: 0.88\n",
            "Specificity: 0.89\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqRg_p1w2car"
      },
      "source": [
        "**3. Select another classifier and compare the results of your model based on the following criteria: Accuracy, Sensitivity and Specificity (10 points)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRh_GYy4zTQ6"
      },
      "source": [
        "silent = False,\r\n",
        "max_depth= 6, 10, 15, 20,\r\n",
        "learning_rate = 0.001, 0.01, 0.1, 0.2, 0,3,\r\n",
        "subsample= 0.5, 0.6, 0.7, 0.8, 0.9, 1.0,\r\n",
        "colsample_bytree= 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0,\r\n",
        "colsample_bylevel= 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0,\r\n",
        "min_child_weight= 0.5, 1.0, 3.0, 5.0, 7.0, 10.0,\r\n",
        "gamma = 0, 0.25, 0.5, 1.0,\r\n",
        "reg_lambda= 0.1, 1.0, 5.0, 10.0, 50.0, 100.0,\r\n",
        "n_estimators = [100]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jq58FihxeMh"
      },
      "source": [
        "model = XGBClassifier()\r\n",
        "param_grid = dict(\r\n",
        "        max_depth = max_depth,\r\n",
        "        learning_rate = learning_rate,\r\n",
        "        subsample = subsample,\r\n",
        "        colsample_bytree = colsample_bytree,\r\n",
        "        colsample_bylevel = colsample_bylevel,\r\n",
        "        min_child_weight = min_child_weight,\r\n",
        "        gamma = gamma,\r\n",
        "        reg_lambda = reg_lambda,\r\n",
        "         n_estimators = n_estimators)\r\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLQSePuUyH8T",
        "outputId": "d3eab14c-770a-45c7-b59b-22130953b5de"
      },
      "source": [
        "xgb_random = RandomizedSearchCV(estimator=model, param_distributions=param_grid, cv=kfold, verbose=2, random_state=42, n_jobs=-1)\r\n",
        "# Fit the random search model\r\n",
        "xgb_random.fit(tfidf_df, Y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed: 52.3min\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 124.3min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=StratifiedKFold(n_splits=10, random_state=7, shuffle=True),\n",
              "                   error_score=nan,\n",
              "                   estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
              "                                           colsample_bylevel=1,\n",
              "                                           colsample_bynode=1,\n",
              "                                           colsample_bytree=1, gamma=0,\n",
              "                                           learning_rate=0.1, max_delta_step=0,\n",
              "                                           max_depth=3, min_child_weight=1,\n",
              "                                           missing=None, n_estimators=100,\n",
              "                                           n_jobs=1, nthread=None,\n",
              "                                           objective='bina...\n",
              "                                                             0.8, 0.9, 1.0),\n",
              "                                        'gamma': (0, 0.25, 0.5, 1.0),\n",
              "                                        'learning_rate': (0.001, 0.01, 0.1, 0.2,\n",
              "                                                          0, 3),\n",
              "                                        'max_depth': (6, 10, 15, 20),\n",
              "                                        'min_child_weight': (0.5, 1.0, 3.0, 5.0,\n",
              "                                                             7.0, 10.0),\n",
              "                                        'n_estimators': [100],\n",
              "                                        'reg_lambda': (0.1, 1.0, 5.0, 10.0,\n",
              "                                                       50.0, 100.0),\n",
              "                                        'subsample': (0.5, 0.6, 0.7, 0.8, 0.9,\n",
              "                                                      1.0)},\n",
              "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
              "                   return_train_score=False, scoring=None, verbose=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ynt80ECDCnFk",
        "outputId": "3a4ba44f-7a72-4bb5-8614-59d299666056"
      },
      "source": [
        "xgb_random.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'colsample_bylevel': 0.4,\n",
              " 'colsample_bytree': 1.0,\n",
              " 'gamma': 0.5,\n",
              " 'learning_rate': 0.1,\n",
              " 'max_depth': 20,\n",
              " 'min_child_weight': 7.0,\n",
              " 'n_estimators': 100,\n",
              " 'reg_lambda': 100.0,\n",
              " 'subsample': 0.8}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AuKGUhXC49p"
      },
      "source": [
        "silent = False,\r\n",
        "max_depth= 20\r\n",
        "learning_rate = 0.1\r\n",
        "subsample= 0.8\r\n",
        "colsample_bytree= 1.0\r\n",
        "colsample_bylevel= 0.4\r\n",
        "min_child_weight= 7.0\r\n",
        "gamma = 0.5\r\n",
        "reg_lambda= 100.0\r\n",
        "n_estimators = [100]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sf7KZC4C7gK"
      },
      "source": [
        "model = XGBClassifier()\r\n",
        "param_grid = dict(\r\n",
        "        max_depth = max_depth,\r\n",
        "        learning_rate = learning_rate,\r\n",
        "        subsample = subsample,\r\n",
        "        colsample_bytree = colsample_bytree,\r\n",
        "        colsample_bylevel = colsample_bylevel,\r\n",
        "        min_child_weight = min_child_weight,\r\n",
        "        gamma = gamma,\r\n",
        "        reg_lambda = reg_lambda,\r\n",
        "         n_estimators = n_estimators)\r\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQCpB7icDg5t",
        "outputId": "4f293c01-32dc-49c2-ba82-b765d103cccc"
      },
      "source": [
        "model.fit(tfidf_train, Y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
              "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
              "              nthread=None, objective='multi:softprob', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuQCUFB8Dvyu"
      },
      "source": [
        "pred = model.predict(tfidf_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsMzCXI4Dyej"
      },
      "source": [
        "pred_prob = model.predict_proba(tfidf_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qltsnX1rD2mY",
        "outputId": "7b348d9e-9438-4f90-c5b3-e319d7bc9e8f"
      },
      "source": [
        "performance(pred, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1-score  : 0.3351578771521648\n",
            "Accuracy  : 0.3499210110584518\n",
            "Precision : 0.4031983584914157\n",
            "Recall    : 0.3349124104298045\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9segj3mYEE80",
        "outputId": "aab82378-3913-4707-a217-74ff940fa6a7"
      },
      "source": [
        "# Print the Confusion Matrix\r\n",
        "cm = confusion_matrix(Y_test, pred)\r\n",
        "print(\"Confusion Matrix\\n\")\r\n",
        "print(cm)\r\n",
        "# Print the Classification Report\r\n",
        "cr = classification_report(Y_test, pred)\r\n",
        "print(\"\\n\\nClassification Report\\n\")\r\n",
        "print(cr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix\n",
            "\n",
            "[[156  12 131  59 234]\n",
            " [ 21 138  58  47 335]\n",
            " [122  29 230 149 511]\n",
            " [  8   7  71 196 337]\n",
            " [ 35  73 116 114 609]]\n",
            "\n",
            "\n",
            "Classification Report\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.26      0.33       592\n",
            "           1       0.53      0.23      0.32       599\n",
            "           2       0.38      0.22      0.28      1041\n",
            "           3       0.35      0.32      0.33       619\n",
            "           4       0.30      0.64      0.41       947\n",
            "\n",
            "    accuracy                           0.35      3798\n",
            "   macro avg       0.40      0.33      0.34      3798\n",
            "weighted avg       0.39      0.35      0.34      3798\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDFJtO6ENH1O"
      },
      "source": [
        "def confusion_metrics (conf_matrix):\r\n",
        "# save confusion matrix and slice into four pieces\r\n",
        "    TP = conf_matrix[1][1]\r\n",
        "    TN = conf_matrix[0][0]\r\n",
        "    FP = conf_matrix[0][1]\r\n",
        "    FN = conf_matrix[1][0]\r\n",
        "    print('True Positives:', TP)\r\n",
        "    print('True Negatives:', TN)\r\n",
        "    print('False Positives:', FP)\r\n",
        "    print('False Negatives:', FN)\r\n",
        "    \r\n",
        "    # calculate the sensitivity\r\n",
        "    conf_sensitivity = (TP / float(TP + FN))\r\n",
        "    # calculate the specificity\r\n",
        "    conf_specificity = (TN / float(TN + FP))\r\n",
        "\r\n",
        "    print(f'Sensitivity: {round(conf_sensitivity,2)}') \r\n",
        "    print(f'Specificity: {round(conf_specificity,2)}') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1zQXHOwNRoz",
        "outputId": "b3ab11fd-2a67-44de-d4fd-39281f4ba979"
      },
      "source": [
        "confusion_metrics(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True Positives: 138\n",
            "True Negatives: 156\n",
            "False Positives: 12\n",
            "False Negatives: 21\n",
            "Sensitivity: 0.87\n",
            "Specificity: 0.93\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXoQ60MD2jA2"
      },
      "source": [
        "**4. Carry out a ROC analysis to compare the performance of your model with the selected classifier. Plot the ROC graph of the models (10 points)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryqJPtZhwxWV"
      },
      "source": [
        "rfc_pred_prob = rfc.predict_proba(tfidf_test)\r\n",
        "model_pred_prob2 = model.predict_proba(tfidf_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdXXQmJNw-IW"
      },
      "source": [
        "# roc curve for models\r\n",
        "fpr1, tpr1, thresh1 = roc_curve(Y_test, rfc_pred_prob[:,1], pos_label=1)\r\n",
        "fpr2, tpr2, thresh2 = roc_curve(Y_test, model_pred_prob2[:,1], pos_label=1)\r\n",
        "\r\n",
        "# roc curve for tpr = fpr \r\n",
        "random_probs = [0 for i in range(len(Y_test))]\r\n",
        "p_fpr, p_tpr, _ = roc_curve(Y_test, random_probs, pos_label=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "id": "xJgkwqnTxGSf",
        "outputId": "75c3dde2-a74f-41f7-8c16-0a683f8596b9"
      },
      "source": [
        "plt.style.use('seaborn')\r\n",
        "\r\n",
        "# plot roc curves\r\n",
        "plt.plot(fpr1, tpr1, linestyle='--',color='darkorange', label='Random Forest')\r\n",
        "plt.plot(fpr2, tpr2, linestyle='--',color='green', label='XG Boost')\r\n",
        "plt.plot(p_fpr, p_tpr, linestyle='--', color='cornflowerblue')\r\n",
        "# title\r\n",
        "plt.title('ROC curve')\r\n",
        "# x label\r\n",
        "plt.xlabel('False Positive Rate')\r\n",
        "# y label\r\n",
        "plt.ylabel('True Positive rate')\r\n",
        "\r\n",
        "plt.legend(loc='best')\r\n",
        "plt.savefig('ROC',dpi=300)\r\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v18DLwcc2rsZ"
      },
      "source": [
        "**5. After tuning your final model, persist using Pickle or Joblib (10 points)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tPyTW66x6bM"
      },
      "source": [
        "filename = 'Random Forest.sav'\r\n",
        "pickle.dump(rfc, open(filename, 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oM4NoLaAx_6m"
      },
      "source": [
        "filename = 'XGBoost.sav'\r\n",
        "pickle.dump(model, open(filename, 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oTAnZK221oV"
      },
      "source": [
        "<H5 align=\"left\"><b> Thank you </b></H5>\r\n",
        "<H5 align=\"left\"><b> Assignment -3 Task - 2: 50 Points </b></H5>\r\n",
        "<H5 align=\"left\"><b> Prepared and Submitted By : Rahul Raj Sharma </b></H5>"
      ]
    }
  ]
}